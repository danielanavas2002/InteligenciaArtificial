{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edcea2d",
   "metadata": {},
   "source": [
    "# **PROYECTO FINAL**\n",
    "**Daniela Navas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32de42b",
   "metadata": {},
   "source": [
    "---\n",
    "### FEATURE SELECTION\n",
    "\n",
    "Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411eb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = [\"MAV\", \"RMS\", \"V\", \"WL\", \"SSC\", \"IEMG\", \"LOGVAR\", \"PF\", \"TP\", \"SE\", \"FR\", \"BW\", \"PSD\", \"P2P\"]\n",
    "clases = [\"reposo\", \"palma\", \"pinza\", \"puno\"]\n",
    "\n",
    "# -----------------------------------------\n",
    "def leer_csv(nombre_archivo):\n",
    "    with open(nombre_archivo, \"r\") as f:\n",
    "        lineas = f.readlines()\n",
    "    encabezados = lineas[0].strip().split(\",\")\n",
    "    datos = []\n",
    "    for linea in lineas[1:]:\n",
    "        partes = linea.strip().split(\",\")\n",
    "        if len(partes) != len(encabezados):\n",
    "            continue\n",
    "        registro = {encabezados[i]: partes[i] for i in range(len(encabezados))}\n",
    "        datos.append(registro)\n",
    "    return datos\n",
    "\n",
    "# -----------------------------------------\n",
    "def dividir_dataset(dataset, training=0.8, semilla=42):\n",
    "    random.seed(semilla)\n",
    "    copia = dataset[:]\n",
    "    random.shuffle(copia)\n",
    "    corte = int(len(copia) * training)\n",
    "    return copia[:corte], copia[corte:]\n",
    "\n",
    "# -----------------------------------------\n",
    "def convertir_a_vectores(dataset, selected_features):\n",
    "    X, y = [], []\n",
    "    for fila in dataset:\n",
    "        X.append([float(fila[f]) for f in selected_features])\n",
    "        y.append(fila[\"MOV\"])\n",
    "    return X, y\n",
    "\n",
    "# -----------------------------------------\n",
    "def calcular_importancia_rf(X, y, features):\n",
    "    importancia = {}\n",
    "    n = len(X)\n",
    "    for i in range(len(features)):\n",
    "        thresholds = sorted(set(row[i] for row in X))\n",
    "        mejor_gini = float(\"inf\")\n",
    "        for t in thresholds:\n",
    "            izquierda = [y[j] for j in range(n) if X[j][i] <= t]\n",
    "            derecha = [y[j] for j in range(n) if X[j][i] > t]\n",
    "            if not izquierda or not derecha:\n",
    "                continue\n",
    "            gini_izq = 1.0 - sum((izquierda.count(c)/len(izquierda))**2 for c in clases)\n",
    "            gini_der = 1.0 - sum((derecha.count(c)/len(derecha))**2 for c in clases)\n",
    "            gini = (len(izquierda)/n)*gini_izq + (len(derecha)/n)*gini_der\n",
    "            if gini < mejor_gini:\n",
    "                mejor_gini = gini\n",
    "        importancia[features[i]] = 1 - mejor_gini  # Mayor importancia = menor Gini\n",
    "    return importancia\n",
    "\n",
    "# -----------------------------------------\n",
    "def rfe(dataset, top_n, semilla):\n",
    "    entrenamiento, _ = dividir_dataset(dataset, semilla=semilla)\n",
    "    remaining_features = features[:]\n",
    "    print(\"Aplicando RFE:\")\n",
    "    while len(remaining_features) > top_n:\n",
    "        X_train, y_train = convertir_a_vectores(entrenamiento, remaining_features)\n",
    "        importancias = calcular_importancia_rf(X_train, y_train, remaining_features)\n",
    "        menos_importante = min(importancias, key=importancias.get)\n",
    "        print(f\" - Eliminando: {menos_importante} (importancia: {importancias[menos_importante]:.4f})\")\n",
    "        remaining_features.remove(menos_importante)\n",
    "    print(f\"\\nCaracterísticas seleccionadas ({top_n}): {remaining_features}\")\n",
    "    return remaining_features\n",
    "\n",
    "# -----------------------------------------\n",
    "def graficar_importancias(importancias, seleccionadas):\n",
    "    ordenadas = sorted(importancias.items(), key=lambda x: x[1], reverse=True)\n",
    "    nombres = [x[0] for x in ordenadas]\n",
    "    valores = [x[1] for x in ordenadas]\n",
    "    colores = [\"green\" if f in seleccionadas else \"gray\" for f in nombres]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(nombres, valores, color=colores)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(\"Recursive Feature Elimination - Importancia de Features (Gini)\")\n",
    "    plt.ylabel(\"Importancia (1 - Gini)\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    for i, val in enumerate(valores):\n",
    "        plt.text(i, val + 0.005, f\"{val:.2f}\", ha='center', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------\n",
    "dataset = leer_csv(\"dataset_completo.csv\")\n",
    "entrenamiento, _ = dividir_dataset(dataset, semilla=42)\n",
    "X_train, y_train = convertir_a_vectores(entrenamiento, features)\n",
    "importancias = calcular_importancia_rf(X_train, y_train, features)\n",
    "\n",
    "seleccionadas = rfe(dataset, top_n=10, semilla=42)\n",
    "\n",
    "graficar_importancias(importancias, seleccionadas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f36cc61",
   "metadata": {},
   "source": [
    "---\n",
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060a0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "features = ['MAV', 'RMS', 'V', 'WL', 'IEMG', 'LOGVAR', 'PF', 'TP', 'PSD', 'P2P']\n",
    "clases = [\"reposo\", \"palma\", \"pinza\", \"puno\"]\n",
    "\n",
    "# -----------------------------------------\n",
    "def leer_csv(nombre_archivo):\n",
    "    with open(nombre_archivo, \"r\") as f:\n",
    "        lineas = f.readlines()\n",
    "    encabezados = lineas[0].strip().split(\",\")\n",
    "    datos = []\n",
    "    for linea in lineas[1:]:\n",
    "        partes = linea.strip().split(\",\")\n",
    "        if len(partes) != len(encabezados):\n",
    "            continue\n",
    "        fila = {encabezados[i]: partes[i] for i in range(len(encabezados))}\n",
    "        datos.append(fila)\n",
    "    return datos\n",
    "\n",
    "# -----------------------------------------\n",
    "def euclidean_distance(a, b):\n",
    "    suma = 0.0\n",
    "    for f in features:\n",
    "        suma += (float(a[f]) - float(b[f])) ** 2\n",
    "    return math.sqrt(suma)\n",
    "\n",
    "# -----------------------------------------\n",
    "def knn(train_set, instancia, k=3):\n",
    "    distancias = []\n",
    "    for elemento in train_set:\n",
    "        dist = euclidean_distance(instancia, elemento)\n",
    "        distancias.append((elemento, dist))\n",
    "    distancias.sort(key=lambda x: x[1])\n",
    "    vecinos = distancias[:k]\n",
    "    etiquetas = [vecino[0][\"MOV\"] for vecino in vecinos]\n",
    "    prediccion = Counter(etiquetas).most_common(1)[0][0]\n",
    "    return prediccion\n",
    "\n",
    "# -----------------------------------------\n",
    "def dividir_dataset(dataset, porcentaje_entrenamiento=0.8, semilla=42):\n",
    "    random.seed(semilla)\n",
    "    copia = dataset[:]\n",
    "    random.shuffle(copia)\n",
    "    corte = int(len(copia) * porcentaje_entrenamiento)\n",
    "    return copia[:corte], copia[corte:]\n",
    "\n",
    "# -----------------------------------------\n",
    "def matriz_confusion(y_verdadero, y_predicho):\n",
    "    matriz = {real: {pred: 0 for pred in clases} for real in clases}\n",
    "    for real, pred in zip(y_verdadero, y_predicho):\n",
    "        matriz[real][pred] += 1\n",
    "    return matriz\n",
    "\n",
    "# -----------------------------------------\n",
    "def metricas_clasificacion(matriz):\n",
    "    print(\"\\nMétricas por clase:\")\n",
    "    total = 0\n",
    "    correctos = 0\n",
    "    for clase in clases:\n",
    "        TP = matriz[clase][clase]\n",
    "        FP = sum(matriz[otra][clase] for otra in clases if otra != clase)\n",
    "        FN = sum(matriz[clase][otra] for otra in clases if otra != clase)\n",
    "        TN = sum(\n",
    "            matriz[otra1][otra2]\n",
    "            for otra1 in clases if otra1 != clase\n",
    "            for otra2 in clases if otra2 != clase\n",
    "        )\n",
    "        total += TP + FN\n",
    "        correctos += TP\n",
    "\n",
    "        sensibilidad = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        especificidad = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "        print(f\"\\nClase: {clase}\")\n",
    "        print(f\"  Sensibilidad  : {sensibilidad:.2f}\")\n",
    "        print(f\"  Especificidad : {especificidad:.2f}\")\n",
    "\n",
    "    exactitud = correctos / total if total > 0 else 0\n",
    "    print(f\"\\nExactitud global: {exactitud:.2f}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "def graficar_matriz_confusion(matriz):\n",
    "    matriz_np = np.array([[matriz[real][pred] for pred in clases] for real in clases])\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(matriz_np, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "                xticklabels=clases, yticklabels=clases, cbar=False)\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(\"Matriz de Confusión - KNN\")\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------\n",
    "def ejecutar_knn(nombre_csv, k=3, seed=42):\n",
    "    datos = leer_csv(nombre_csv)\n",
    "    entrenamiento, prueba = dividir_dataset(datos, porcentaje_entrenamiento=0.8, semilla=seed)\n",
    "\n",
    "    y_verdadero = []\n",
    "    y_predicho = []\n",
    "\n",
    "    for ejemplo in prueba:\n",
    "        y_verdadero.append(ejemplo[\"MOV\"])\n",
    "        pred = knn(entrenamiento, ejemplo, k)\n",
    "        y_predicho.append(pred)\n",
    "\n",
    "    matriz = matriz_confusion(y_verdadero, y_predicho)\n",
    "\n",
    "    print(\"\\nMatriz de Confusión:\")\n",
    "    print(\"               Predicho\")\n",
    "    print(\"          \", \"  \".join([f\"{c:^7}\" for c in clases]))\n",
    "    print(\"Real\")\n",
    "    for real in clases:\n",
    "        fila = \" \".join([f\"{matriz[real][pred]:^7}\" for pred in clases])\n",
    "        print(f\"{real:<9} {fila}\")\n",
    "\n",
    "    metricas_clasificacion(matriz)\n",
    "    graficar_matriz_confusion(matriz)\n",
    "\n",
    "\n",
    "ejecutar_knn(\"dataset_completo.csv\", k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63575a76",
   "metadata": {},
   "source": [
    "---\n",
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "features = ['MAV', 'RMS', 'V', 'WL', 'IEMG', 'LOGVAR', 'PF', 'TP', 'PSD', 'P2P']\n",
    "clases = [\"reposo\", \"palma\", \"pinza\", \"puno\"]\n",
    "\n",
    "# -------------------------------------\n",
    "def leer_csv(nombre_archivo):\n",
    "    with open(nombre_archivo, \"r\") as f:\n",
    "        lineas = f.readlines()\n",
    "    encabezados = lineas[0].strip().split(\",\")\n",
    "    datos = []\n",
    "    for linea in lineas[1:]:\n",
    "        partes = linea.strip().split(\",\")\n",
    "        if len(partes) != len(encabezados):\n",
    "            continue\n",
    "        fila = {encabezados[i]: partes[i] for i in range(len(encabezados))}\n",
    "        datos.append(fila)\n",
    "    return datos\n",
    "\n",
    "# -------------------------------------\n",
    "def dividir_dataset(dataset, porcentaje_entrenamiento=0.8, semilla=42):\n",
    "    random.seed(semilla)\n",
    "    copia = dataset[:]\n",
    "    random.shuffle(copia)\n",
    "    corte = int(len(copia) * porcentaje_entrenamiento)\n",
    "    return copia[:corte], copia[corte:]\n",
    "\n",
    "# -------------------------------------\n",
    "def convertir_a_vectores(dataset):\n",
    "    X = []\n",
    "    y = []\n",
    "    for fila in dataset:\n",
    "        x = [float(fila[f]) for f in features]\n",
    "        X.append(x)\n",
    "        y.append(fila[\"MOV\"])\n",
    "    return X, y\n",
    "\n",
    "# -------------------------------------\n",
    "def entrenar_svm_binario(X, y_binario, epochs=200, lr=0.005, lam=0.001):\n",
    "    w = [0.0 for _ in range(len(X[0]))]\n",
    "    b = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(X)):\n",
    "            xi = X[i]\n",
    "            yi = y_binario[i]\n",
    "            margin = yi * (sum(w[j]*xi[j] for j in range(len(xi))) + b)\n",
    "            if margin >= 1:\n",
    "                for j in range(len(w)):\n",
    "                    w[j] -= lr * (2 * lam * w[j])\n",
    "            else:\n",
    "                for j in range(len(w)):\n",
    "                    w[j] -= lr * (2 * lam * w[j] - yi * xi[j])\n",
    "                b += lr * yi\n",
    "    return w, b\n",
    "\n",
    "# -------------------------------------\n",
    "def entrenar_svm_multiclase(X, y, clases):\n",
    "    modelos = {}\n",
    "    for clase in clases:\n",
    "        y_bin = [1 if etiqueta == clase else -1 for etiqueta in y]\n",
    "        w, b = entrenar_svm_binario(X, y_bin)\n",
    "        modelos[clase] = (w, b)\n",
    "    return modelos\n",
    "\n",
    "# -------------------------------------\n",
    "def predecir_svm_multiclase(X, modelos):\n",
    "    predicciones = []\n",
    "    for xi in X:\n",
    "        scores = {}\n",
    "        for clase in modelos:\n",
    "            w, b = modelos[clase]\n",
    "            score = sum(w[j]*xi[j] for j in range(len(xi))) + b\n",
    "            scores[clase] = score\n",
    "        predicciones.append(max(scores, key=scores.get))\n",
    "    return predicciones\n",
    "\n",
    "# -------------------------------------\n",
    "def matriz_confusion(y_real, y_pred):\n",
    "    matriz = {real: {pred: 0 for pred in clases} for real in clases}\n",
    "    for real, pred in zip(y_real, y_pred):\n",
    "        matriz[real][pred] += 1\n",
    "    return matriz\n",
    "\n",
    "def metricas_clasificacion(matriz):\n",
    "    print(\"\\nMétricas por clase:\")\n",
    "    total = 0\n",
    "    correctos = 0\n",
    "    for clase in clases:\n",
    "        TP = matriz[clase][clase]\n",
    "        FP = sum(matriz[otra][clase] for otra in clases if otra != clase)\n",
    "        FN = sum(matriz[clase][otra] for otra in clases if otra != clase)\n",
    "        TN = sum(\n",
    "            matriz[otra1][otra2]\n",
    "            for otra1 in clases if otra1 != clase\n",
    "            for otra2 in clases if otra2 != clase\n",
    "        )\n",
    "        total += TP + FN\n",
    "        correctos += TP\n",
    "\n",
    "        sensibilidad = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        especificidad = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "        print(f\"\\nClase: {clase}\")\n",
    "        print(f\"  Sensibilidad  : {sensibilidad:.2f}\")\n",
    "        print(f\"  Especificidad : {especificidad:.2f}\")\n",
    "\n",
    "    exactitud = correctos / total if total > 0 else 0\n",
    "    print(f\"\\nExactitud global: {exactitud:.2f}\")\n",
    "\n",
    "# -------------------------------------\n",
    "def graficar_matriz_confusion(matriz):\n",
    "    matriz_np = np.array([[matriz[real][pred] for pred in clases] for real in clases])\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(matriz_np, annot=True, fmt=\"d\", cmap=\"Purples\",\n",
    "                xticklabels=clases, yticklabels=clases, cbar=False)\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(\"Matriz de Confusión - SVM\")\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------\n",
    "def ejecutar_svm(nombre_csv, seed=42):\n",
    "    datos = leer_csv(nombre_csv)\n",
    "    train_data, test_data = dividir_dataset(datos, semilla=seed)\n",
    "\n",
    "    X_train, y_train = convertir_a_vectores(train_data)\n",
    "    X_test, y_test = convertir_a_vectores(test_data)\n",
    "\n",
    "    modelos = entrenar_svm_multiclase(X_train, y_train, clases)\n",
    "    predicciones = predecir_svm_multiclase(X_test, modelos)\n",
    "\n",
    "    matriz = matriz_confusion(y_test, predicciones)\n",
    "\n",
    "    print(\"\\nMatriz de Confusión:\")\n",
    "    print(\"               Predicho\")\n",
    "    print(\"          \", \"  \".join([f\"{c:^7}\" for c in clases]))\n",
    "    print(\"Real\")\n",
    "    for real in clases:\n",
    "        fila = \" \".join([f\"{matriz[real][pred]:^7}\" for pred in clases])\n",
    "        print(f\"{real:<9} {fila}\")\n",
    "\n",
    "    metricas_clasificacion(matriz)\n",
    "    graficar_matriz_confusion(matriz)\n",
    "\n",
    "ejecutar_svm(\"dataset_completo.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e6e4b7",
   "metadata": {},
   "source": [
    "---\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2431b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features = ['MAV', 'RMS', 'V', 'WL', 'IEMG', 'LOGVAR', 'PF', 'TP', 'PSD', 'P2P']\n",
    "clases = [\"reposo\", \"palma\", \"pinza\", \"puno\"]\n",
    "\n",
    "# -------------------------------------\n",
    "def leer_csv(nombre_archivo):\n",
    "    with open(nombre_archivo, \"r\") as f:\n",
    "        lineas = f.readlines()\n",
    "    encabezados = lineas[0].strip().split(\",\")\n",
    "    datos = []\n",
    "    for linea in lineas[1:]:\n",
    "        partes = linea.strip().split(\",\")\n",
    "        if len(partes) != len(encabezados):\n",
    "            continue\n",
    "        fila = {encabezados[i]: partes[i] for i in range(len(encabezados))}\n",
    "        datos.append(fila)\n",
    "    return datos\n",
    "\n",
    "def dividir_dataset(dataset, porcentaje_entrenamiento=0.8, semilla=42):\n",
    "    random.seed(semilla)\n",
    "    copia = dataset[:]\n",
    "    random.shuffle(copia)\n",
    "    corte = int(len(copia) * porcentaje_entrenamiento)\n",
    "    return copia[:corte], copia[corte:]\n",
    "\n",
    "def convertir_a_vectores(dataset):\n",
    "    X = []\n",
    "    y = []\n",
    "    for fila in dataset:\n",
    "        x = [float(fila[f]) for f in features]\n",
    "        X.append(x)\n",
    "        y.append(fila[\"MOV\"])\n",
    "    return X, y\n",
    "\n",
    "def graficar_matriz_confusion(matriz):\n",
    "    matriz_np = np.array([[matriz[real][pred] for pred in clases] for real in clases])\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(matriz_np, annot=True, fmt=\"d\", cmap=\"Oranges\",\n",
    "                xticklabels=clases, yticklabels=clases, cbar=False)\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(\"Matriz de Confusión - Naive Bayes\")\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------\n",
    "# Naive Bayes\n",
    "def calcular_parametros(X, y):\n",
    "    params = {}\n",
    "    for clase in clases:\n",
    "        indices = [i for i in range(len(y)) if y[i] == clase]\n",
    "        clase_features = [X[i] for i in indices]\n",
    "        n = len(clase_features)\n",
    "        medias = [sum(f[j] for f in clase_features) / n for j in range(len(features))]\n",
    "        varianzas = []\n",
    "        for j in range(len(features)):\n",
    "            var = sum((f[j] - medias[j])**2 for f in clase_features) / n\n",
    "            varianzas.append(var if var > 1e-6 else 1e-6)  # evitar división por cero\n",
    "        params[clase] = {\"media\": medias, \"var\": varianzas, \"prior\": n / len(y)}\n",
    "    return params\n",
    "\n",
    "def gaussiana(x, media, var):\n",
    "    exp = math.exp(-(x - media)**2 / (2 * var))\n",
    "    return (1 / math.sqrt(2 * math.pi * var)) * exp\n",
    "\n",
    "def predecir(X, params):\n",
    "    predicciones = []\n",
    "    for xi in X:\n",
    "        probs = {}\n",
    "        for clase in clases:\n",
    "            media = params[clase][\"media\"]\n",
    "            var = params[clase][\"var\"]\n",
    "            prior = params[clase][\"prior\"]\n",
    "            prob = math.log(prior)\n",
    "            for j in range(len(xi)):\n",
    "                p = gaussiana(xi[j], media[j], var[j])\n",
    "                prob += math.log(p if p > 1e-10 else 1e-10)  # evitar log(0)\n",
    "            probs[clase] = prob\n",
    "        predicciones.append(max(probs, key=probs.get))\n",
    "    return predicciones\n",
    "\n",
    "# -------------------------------------\n",
    "# Métricas\n",
    "def matriz_confusion(y_real, y_pred):\n",
    "    matriz = {real: {pred: 0 for pred in clases} for real in clases}\n",
    "    for real, pred in zip(y_real, y_pred):\n",
    "        matriz[real][pred] += 1\n",
    "    return matriz\n",
    "\n",
    "def metricas_clasificacion(matriz):\n",
    "    print(\"\\nMétricas por clase:\")\n",
    "    total = 0\n",
    "    correctos = 0\n",
    "    for clase in clases:\n",
    "        TP = matriz[clase][clase]\n",
    "        FP = sum(matriz[otra][clase] for otra in clases if otra != clase)\n",
    "        FN = sum(matriz[clase][otra] for otra in clases if otra != clase)\n",
    "        TN = sum(\n",
    "            matriz[otra1][otra2]\n",
    "            for otra1 in clases if otra1 != clase\n",
    "            for otra2 in clases if otra2 != clase\n",
    "        )\n",
    "        total += TP + FN\n",
    "        correctos += TP\n",
    "\n",
    "        sensibilidad = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        especificidad = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "        print(f\"\\nClase: {clase}\")\n",
    "        print(f\"  Sensibilidad  : {sensibilidad:.2f}\")\n",
    "        print(f\"  Especificidad : {especificidad:.2f}\")\n",
    "\n",
    "    exactitud = correctos / total if total > 0 else 0\n",
    "    print(f\"\\nExactitud global: {exactitud:.2f}\")\n",
    "\n",
    "# -------------------------------------\n",
    "def ejecutar_naive_bayes(nombre_csv, seed=42):\n",
    "    datos = leer_csv(nombre_csv)\n",
    "    train_data, test_data = dividir_dataset(datos, semilla=seed)\n",
    "\n",
    "    X_train, y_train = convertir_a_vectores(train_data)\n",
    "    X_test, y_test = convertir_a_vectores(test_data)\n",
    "\n",
    "    params = calcular_parametros(X_train, y_train)\n",
    "    predicciones = predecir(X_test, params)\n",
    "\n",
    "    matriz = matriz_confusion(y_test, predicciones)\n",
    "\n",
    "    print(\"\\nMatriz de Confusión:\")\n",
    "    print(\"               Predicho\")\n",
    "    print(\"          \", \"  \".join([f\"{c:^7}\" for c in clases]))\n",
    "    print(\"Real\")\n",
    "    for real in clases:\n",
    "        fila = \" \".join([f\"{matriz[real][pred]:^7}\" for pred in clases])\n",
    "        print(f\"{real:<9} {fila}\")\n",
    "\n",
    "    metricas_clasificacion(matriz)\n",
    "    graficar_matriz_confusion(matriz)\n",
    "\n",
    "ejecutar_naive_bayes(\"dataset_completo.csv\", seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded39a97",
   "metadata": {},
   "source": [
    "---\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "from math import sqrt\n",
    "\n",
    "features = ['MAV', 'RMS', 'V', 'WL', 'IEMG', 'LOGVAR', 'PF', 'TP', 'PSD', 'P2P']\n",
    "clases = [\"reposo\", \"palma\", \"pinza\", \"puno\"]\n",
    "\n",
    "def leer_csv(nombre_archivo):\n",
    "    with open(nombre_archivo, \"r\") as f:\n",
    "        lineas = f.readlines()\n",
    "    encabezados = lineas[0].strip().split(\",\")\n",
    "    datos = []\n",
    "    for linea in lineas[1:]:\n",
    "        partes = linea.strip().split(\",\")\n",
    "        if len(partes) != len(encabezados):\n",
    "            continue\n",
    "        registro = {encabezados[i]: partes[i] for i in range(len(encabezados))}\n",
    "        datos.append(registro)\n",
    "    return datos\n",
    "\n",
    "def dividir_dataset(dataset, training=0.8, semilla=42):\n",
    "    random.seed(semilla)\n",
    "    copia = dataset[:]\n",
    "    random.shuffle(copia)\n",
    "    corte = int(len(copia) * training)\n",
    "    return copia[:corte], copia[corte:]\n",
    "\n",
    "def convertir_a_vectores(dataset, selected_features):\n",
    "    X, y = [], []\n",
    "    for fila in dataset:\n",
    "        X.append([float(fila[f]) for f in selected_features])\n",
    "        y.append(fila[\"MOV\"])\n",
    "    return X, y\n",
    "\n",
    "def distancia_euclidiana(a, b):\n",
    "    return sqrt(sum((x - y) ** 2 for x, y in zip(a, b)))\n",
    "\n",
    "def random_forest_simplificado(X_train, y_train, X_test, k=5):\n",
    "    predicciones = []\n",
    "    for x in X_test:\n",
    "        distancias = [(i, distancia_euclidiana(x, X_train[i])) for i in range(len(X_train))]\n",
    "        distancias.sort(key=lambda x: x[1])\n",
    "        vecinos = [y_train[i] for i, _ in distancias[:k]]\n",
    "        predicciones.append(Counter(vecinos).most_common(1)[0][0])\n",
    "    return predicciones\n",
    "\n",
    "def graficar_matriz_confusion(matriz):\n",
    "    matriz_np = np.array([[matriz[real][pred] for pred in clases] for real in clases])\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(matriz_np, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=clases, yticklabels=clases, cbar=False)\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(\"Matriz de Confusión - Random Forest\")\n",
    "    plt.show()\n",
    "\n",
    "def matriz_confusion(y_real, y_pred):\n",
    "    matriz = {real: {pred: 0 for pred in clases} for real in clases}\n",
    "    for real, pred in zip(y_real, y_pred):\n",
    "        matriz[real][pred] += 1\n",
    "    return matriz\n",
    "\n",
    "def metricas_clasificacion(matriz):\n",
    "    print(\"\\nMétricas por clase:\")\n",
    "    total = 0\n",
    "    correctos = 0\n",
    "    for clase in clases:\n",
    "        TP = matriz[clase][clase]\n",
    "        FP = sum(matriz[otra][clase] for otra in clases if otra != clase)\n",
    "        FN = sum(matriz[clase][otra] for otra in clases if otra != clase)\n",
    "        TN = sum(\n",
    "            matriz[otra1][otra2]\n",
    "            for otra1 in clases if otra1 != clase\n",
    "            for otra2 in clases if otra2 != clase\n",
    "        )\n",
    "        total += TP + FN\n",
    "        correctos += TP\n",
    "\n",
    "        sensibilidad = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        especificidad = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "        print(f\"\\nClase: {clase}\")\n",
    "        print(f\"  Sensibilidad  : {sensibilidad:.2f}\")\n",
    "        print(f\"  Especificidad : {especificidad:.2f}\")\n",
    "\n",
    "    exactitud = correctos / total if total > 0 else 0\n",
    "    print(f\"\\nExactitud global: {exactitud:.2f}\")\n",
    "\n",
    "def ejecutar_rf(nombre_csv, k=5, seed=42):\n",
    "    datos = leer_csv(nombre_csv)\n",
    "    entrenamiento, prueba = dividir_dataset(datos, semilla=seed)\n",
    "    X_train, y_train = convertir_a_vectores(entrenamiento, features)\n",
    "    X_test, y_test = convertir_a_vectores(prueba, features)\n",
    "\n",
    "    y_pred = random_forest_simplificado(X_train, y_train, X_test, k)\n",
    "\n",
    "    matriz = matriz_confusion(y_test, y_pred)\n",
    "\n",
    "    print(\"\\nMatriz de Confusión:\")\n",
    "    print(\"               Predicho\")\n",
    "    print(\"          \", \"  \".join([f\"{c:^7}\" for c in clases]))\n",
    "    print(\"Real\")\n",
    "    for real in clases:\n",
    "        fila = \" \".join([f\"{matriz[real][pred]:^7}\" for pred in clases])\n",
    "        print(f\"{real:<9} {fila}\")\n",
    "\n",
    "    metricas_clasificacion(matriz)\n",
    "    graficar_matriz_confusion(matriz)\n",
    "  \n",
    "\n",
    "# Ejecutar\n",
    "ejecutar_rf(\"dataset_completo.csv\", k=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
