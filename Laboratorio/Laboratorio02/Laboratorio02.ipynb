{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Laboratorio 2**\n",
    "**Daniela Navas**\n",
    "\n",
    "## **Task 1** - Preguntas Teóricas\n",
    "\n",
    "**1. ¿Por qué el modelo de Naive Bayes se le considera “naive”?**<br>\n",
    "Se considera *ingenuo* debido a la suposición de que las características o predictores en un conjunto de datos son independientes entre sí, lo que se conoce como independencia condicional de clase. Esta suposición simplifica el cálculo de las probabilidades, ya que solo se necesita calcular la probabilidad de cada característica de forma individual, sin considerar las interacciones entre ellas. Aunque esta suposición no siempre se cumple en la realidad, donde las características suelen estar interrelacionadas, el algoritmo sigue siendo efectivo y fácil de implementar, especialmente con grandes conjuntos de datos.\n",
    "\n",
    "\n",
    "**2. Explique la formulación matemática que se busca optimizar en Support Vector Machine, además responda ¿cómo funciona el truco del Kernel para este modelo? (Lo que se espera de esta pregunta es que puedan explicar en sus propias palabras la fórmula a la que llegamos que debemos optimizar de SVM en clase)**<br>\n",
    "**Support Vector Machine**<br>\n",
    "En Support Vector Machine (SVM), el objetivo es encontrar el hiperplano que mejor separa las clases en el espacio de características.<br> \n",
    "Primero se determina un hiperplano que separe dos clases de datos en un espacio de características. El hiperplano se define por la ecuación:\n",
    "\n",
    "$$\\mathbf{w} \\cdot \\mathbf{x} + b = 0$$\n",
    "\n",
    "donde:\n",
    "- Vector de pesos: $ \\mathbf{w} $\n",
    "- Sesgo (bias): $ b $\n",
    "- Vector de características: $ \\mathbf{x} $\n",
    "\n",
    "\n",
    "Para que los datos estén correctamente clasificados, se deben cumplir las siguientes condiciones:\n",
    "- Para puntos de la clase $+1$: $ \\mathbf{w} \\cdot \\mathbf{x}_i + b \\geq 1 $\n",
    "- Para puntos de la clase $-1$: $ \\mathbf{w} \\cdot \\mathbf{x}_i + b \\leq -1 $\n",
    "\n",
    "Combinandolas en una sola:\n",
    "\n",
    "$$y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1 \\quad \\forall i$$\n",
    "\n",
    "donde $y_i$ es la etiqueta de la clase (+1 o -1).\n",
    "\n",
    "El margen es la distancia entre los puntos más cercanos de cada clase y el hiperplano. Queremos maximizar este margen. La distancia de un punto al hiperplano es:\n",
    "\n",
    "$$\\frac{1}{\\|\\mathbf{w}\\|}$$\n",
    "\n",
    "Para maximizar el margen, minimizamos $\\|\\mathbf{w}\\|$. Sin embargo, para simplificar los cálculos, minimizamos $\\frac{1}{2} \\|\\mathbf{w}\\|^2$ en su lugar.\n",
    "\n",
    "El problema de optimización se formula como:\n",
    "\n",
    "$$\\min_{\\mathbf{w}, b} \\frac{1}{2} \\|\\mathbf{w}\\|^2$$\n",
    "\n",
    "sujeto a las restricciones:\n",
    "\n",
    "$$y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1 \\quad \\forall i$$\n",
    "\n",
    "Esto nos lleva a un problema de optimización cuadrática con restricciones lineales. Se puede resolver usando métodos como los multiplicadores de Lagrange y técnicas de programación cuadrática.\n",
    "\n",
    "Si los datos no son linealmente separables en el espacio original, utilizamos el truco del Kernel para mapear los datos a un espacio de mayor dimensión donde sí sean separables. Esto se hace mediante una función de kernel $K(\\mathbf{x}_i, \\mathbf{x}_j)$ que calcula el producto interno en el espacio transformado.\n",
    "\n",
    "**Truco del Kernel**<br>\n",
    "El truco del Kernel permite a SVM manejar datos que no son linealmente separables en el espacio original de características. La idea es transformar los datos a un espacio de mayor dimensión donde sí sean linealmente separables. Esto se hace mediante una función de kernel $K(\\mathbf{x}_i, \\mathbf{x}_j)$ que calcula el producto interno en el espacio transformado sin necesidad de calcular explícitamente la transformación.\n",
    "\n",
    "Si hay un conjunto de datos $\\{\\mathbf{x}_i, y_i\\}$ donde $\\mathbf{x}_i$ es el vector de características y $y_i$ es la etiqueta de clase. En el espacio original, los datos no son linealmente separables.\n",
    "\n",
    "Queremos transformar los datos a un espacio de mayor dimensión utilizando una función de transformación $\\phi(\\mathbf{x})$. Sin embargo, calcular explícitamente $\\phi(\\mathbf{x})$ puede ser computacionalmente costoso.\n",
    "\n",
    "En lugar de calcular $\\phi(\\mathbf{x})$ directamente, utilizamos una función de kernel $K(\\mathbf{x}_i, \\mathbf{x}_j)$ que calcula el producto interno en el espacio transformado:\n",
    "\n",
    "$$K(\\mathbf{x}_i, \\mathbf{x}_j) = \\phi(\\mathbf{x}_i) \\cdot \\phi(\\mathbf{x}_j)$$\n",
    "\n",
    "\n",
    "**3. Investigue sobre Random Forest y responda**<br>  \n",
    "**a. ¿Qué tipo de ensemble learning es este modelo?**<br> \n",
    "Random Forest es un ejemplo de bagging (bootstrap aggregating). En este enfoque, se generan múltiples modelos (en este caso, árboles de decisión) entrenados en diferentes subconjuntos de datos obtenidos mediante muestreo con reemplazo. Este método busca reducir la varianza y mejorar la estabilidad del modelo al promediar las predicciones de varios árboles.\n",
    "\n",
    "**b. ¿Cuál es la idea general detrás de Random Forest?**<br> \n",
    "Crear un conjunto de árboles de decisión que trabajan juntos para mejorar la precisión de las predicciones. Cada árbol es entrenado con una muestra aleatoria de los datos y, durante el proceso de construcción, se selecciona un subconjunto aleatorio de características para cada división en el árbol. Esto permite que los árboles sean diversos y, al final, sus resultados se combinan mediante votación (en clasificación) o promediación (en regresión) para obtener una predicción final más robusta.\n",
    "\n",
    "**c. ¿Por qué se busca baja correlación entre los árboles de Random Forest?**<br>\n",
    "La baja correlación entre los árboles en un modelo de Random Forest es crucial porque permite que cada árbol capture diferentes patrones en los datos. Si los árboles están muy correlacionados, sus errores también lo estarán, lo que puede llevar a una reducción limitada en la varianza del modelo. Al promover la diversidad entre los árboles, se mejora la capacidad del modelo para generalizar a nuevos datos y se reduce el riesgo de sobreajuste. Este enfoque asegura que la combinación de las predicciones sea más efectiva y robusta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 2** -  Naive Bayes: Clasificador de Mensajes Ham/Spam<br>\n",
    "Deberá construir un programa que reciba como entrada un archivo llamado “entrenamiento.txt” que será su dataset para entrenar un modelo basado en Bayes/Laplace Smoothing para clasificar mensajes como ham o spam. De dicho modelo, deberá reportar alguna métrica de desempeño. Además, con dicho modelo deberá ser capaz de interpretar mensajes futuros como spam o ham. Asimismo, deberá considerar las siguientes restricciones: \n",
    "- Solamente se podrá entrenar un modelo por dataset de entrenamiento (No se pueden cargar más de un archivo para entrenar el modelo) \n",
    "- Deberá limpiar el dataset de caracteres especiales y de combinaciones de mayúsculas/minúsculas. \n",
    "- Cada línea representa una observación (mensaje con su respectiva categoría) \n",
    "-  Del dataset dado deberá dividirlo en training y test. \n",
    "    - Para este punto, podrá usar librerías externas como las dadas en sklearn.  \n",
    "    - **NO** se aceptará el uso de librerías para la construcción del modelo principal\n",
    "\n",
    "### **Task 2.1** - Lectura y limpieza del dataset<br> \n",
    "Reciba como entrada un archivo llamado “entrenamiento.txt” que tendrá una estructura como la que se muestra \n",
    "abajo. En dicho archivo, cada línea representa un mensaje, y la primera palabra de la línea indica si es un mensaje \n",
    "Ham o Spam (etiqueta/categoría del mensaje), luego encuentra una tabulación (\\t) para separar la etiqueta del \n",
    "verdadero mensaje, finalmente está el mensaje que termina hasta que encuentre un cambio de línea (\\n). En base a \n",
    "este archivo, usted deberá entrenar un modelo basado en Bayes con Laplace Smoothing para clasificar mensajes \n",
    "como spam o ham.<br>  \n",
    "Además, deberá limpiar el archivo de texto, teniendo en cuenta que pueden haber caracteres especiales que \n",
    "solamente agreguen ruido al mensaje y otros que pueden llegar a ser de utilidad para la clasificación. De igual modo, \n",
    "se recomienda cambiar los mensajes a que todos sigan la misma nomenclatura, es decir, todo en mayúsculas o bien, \n",
    "todo en minúscula, o similar, de modo tal que pueda clasificar de mejor manera la participación de cada palabra para \n",
    "determinar la categoría del mensaje.<br>   \n",
    "También, deberá separar el dataset con un 80% para training, 20% para testing. Si llegan a necesitar una parte para \n",
    "validation, pueden subdividir el 20% de testing en 10% para validation y 10% para testing. Recuerden que esta división \n",
    "siempre deberá ser realizada de forma aleatoria, para reproducir sus resultados usen una seed.<br>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Abrir archivo \n",
    "with open(\"entrenamiento.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Convertir en un set donde se tenga la etiqueta y el mensaje\n",
    "data = []\n",
    "for line in lines:\n",
    "    parts = line.strip().split(\"\\t\", 1)  # Separar solo en la primera tabulación\n",
    "    if len(parts) == 2:\n",
    "        label, message = parts\n",
    "        data.append((label, message)) # Nombrar \"label\" si es Spam o Ham; y \"message\" al contenido en si del mensaje\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"label\", \"message\"])\n",
    "\n",
    "# Limpieza de datos | Eliminar ruido\n",
    "def clean_text(text):\n",
    "    text = text.lower()                      # Convertir a minúsculas (Normalizar)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # Eliminar caracteres especiales (Filtro ruido)\n",
    "    return text\n",
    "\n",
    "df[\"message\"] = df[\"message\"].apply(clean_text) # Despues de separar, aplicar limpieza a todos los datos\n",
    "\n",
    "# División en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2.2** - Construcción del modelo<br> \n",
    "Una vez tenga una forma de leer y limpiar el dataset, deberá crear un modelo basado en Bayes con Laplace Smoothing para que clasifique los mensajes en spam o ham. Esto deberá basarse en la probabilidad de cada palabra en pertenecer a cada uno de los posibles grupos. Cuando tenga la probabilidad del mensaje que sea spam o ham, deberá clasificarlo con la probabilidad de la categoría que resulte mayor.<br>  \n",
    "Es importante tomar en cuenta que el entrenamiento y construcción del modelo deberá hacerse usando solamente la parte de training del dataset.<br>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Entenamiento basado en probabilidad de Bayes \n",
    "def entrenar_bayes(mensajes, etiquetas, alpha=1):\n",
    "    vocabulario = set()                                                     # Almacenar palabras únicas\n",
    "    conteo_palabras = {'ham': defaultdict(int), 'spam': defaultdict(int)}   # Contar cuantas veces aparece cada palabra en spam y ham\n",
    "    total_palabras = {'ham': 0, 'spam': 0}                                  # Total de palabras en spam y ham\n",
    "    total_mensajes = {'ham': 0, 'spam': 0}                                  # Total de mensajes spam y ham\n",
    "    \n",
    "    for mensaje, etiqueta in zip(mensajes, etiquetas): # Recorrer cada mensaje y: \n",
    "        total_mensajes[etiqueta] += 1                  # Sumar en ham o spam, según corresponde\n",
    "        palabras = mensaje.split()                     # Separar palabras \n",
    "        for palabra in palabras:                       # Contar cuantas veces aparece cada palabra en cada una de sus categorías. \n",
    "            vocabulario.add(palabra)\n",
    "            conteo_palabras[etiqueta][palabra] += 1\n",
    "            total_palabras[etiqueta] += 1              # Sumar en la cuenta general de palabras\n",
    "    \n",
    "    return vocabulario, conteo_palabras, total_palabras, total_mensajes #Retorna valores necesarios para el calculo de la probabilidad usando Bayes \n",
    "\n",
    "# Cálculo de Probabilidades usando Naive Bayes con Laplace Smoothing\n",
    "def calcular_probabilidades(mensaje, vocabulario, conteo_palabras, total_palabras, total_mensajes, alpha=1): # Recibe valores del conteo que se hizo previamente \n",
    "    categorias = ['ham', 'spam']                         # Se tiene spam o ham\n",
    "    total_mensajes_total = sum(total_mensajes.values())  \n",
    "    probabilidades = {}\n",
    "    palabras = mensaje.split()\n",
    "    \n",
    "    for categoria in categorias: # Recorrer Spam y ham\n",
    "        prob_categoria = np.log(total_mensajes[categoria] / total_mensajes_total) # Proabilidad de uno u otro | Uso de log ya que al multiplicar probabilidades se obtienen cantidades pequeñas por lo que se toma el logaritmo de cada una y se suman, lo que evita que los valores se reduzcan demasiado.\n",
    "        prob_palabras = 0 # Iniciar en cero\n",
    "        for palabra in palabras: # Recorrer todas las palabras \n",
    "            conteo = conteo_palabras[categoria][palabra] + alpha # Laplace Smoothing para evitar probabilidades de cero\n",
    "            prob_palabras += np.log(conteo / (total_palabras[categoria] + alpha * len(vocabulario)))\n",
    "        probabilidades[categoria] = prob_categoria + prob_palabras \n",
    "    \n",
    "    return max(probabilidades, key=probabilidades.get) # Retornar la categoría con mayor probabilidad (Spam o Ham)\n",
    "\n",
    "def predecir(mensajes, vocabulario, conteo_palabras, total_palabras, total_mensajes): # Maximixar el proceso definiendo función que aplica calcular_probabilidades a cada mensaje para predecir su categoría\n",
    "    return [calcular_probabilidades(mensaje, vocabulario, conteo_palabras, total_palabras, total_mensajes) for mensaje in mensajes]\n",
    "\n",
    "# Entrenamiento de modelo usando la data de entrenamineto (train_data)\n",
    "vocabulario, conteo_palabras, total_palabras, total_mensajes = entrenar_bayes(train_data[\"message\"], train_data[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando ya tengan entrenado su modelo, deberán probar el modelo usando la parte de testing del dataset. La métrica a utilizar deberá proponerla considerando la distribución de clases/categorías en el dataset. Recuerde dejar justificada su respuesta en los comentarios de su código.<br>  \n",
    "Presente al final del entrenamiento, la métrica de desempeño sobre el subset de training y sobre el subset de testing.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST DATA ---\n",
      "Matriz de confusión:\n",
      "TP: 157, FP: 18\n",
      "FN: 6, TN: 932\n",
      "------------------------------------------\n",
      "Precisión: 89.71428571428571 %\n",
      "Sensibilidad: 96.31901840490798  %\n",
      "Especificidad: 98.10526315789474  %\n",
      "\n",
      "--- TRAIN DATA ---\n",
      "Matriz de confusión:\n",
      "TP: 559, FP: 14\n",
      "FN: 25, TN: 3854\n",
      "------------------------------------------\n",
      "Precisión: 97.55671902268762 %\n",
      "Sensibilidad: 95.71917808219177  %\n",
      "Especificidad: 99.63805584281282  %\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el rendimiento del modelo usando la data de prueba (test_data) y lo obtenido del modelo entrenado\n",
    "predicciones = predecir(test_data[\"message\"], vocabulario, conteo_palabras, total_palabras, total_mensajes)\n",
    "\n",
    "train_predicciones = predecir(train_data[\"message\"], vocabulario, conteo_palabras, total_palabras, total_mensajes) # Luego tambien en train (Se pide en el enunciado)\n",
    "\n",
    "# Obtención de métricas de rendimiento\n",
    "# Matriz de confusión\n",
    "labels = ['ham', 'spam']\n",
    "cm = confusion_matrix(test_data[\"label\"], predicciones, labels=labels)\n",
    "TP = cm[1, 1]  # spam correctamente clasificado\n",
    "FP = cm[0, 1]  # ham clasificado como spam\n",
    "FN = cm[1, 0]  # spam clasificado como ham\n",
    "TN = cm[0, 0]  # ham correctamente clasificado\n",
    "\n",
    "# Calcular métricas\n",
    "precision_metric = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "sensibilidad = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "especificidad = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "\n",
    "# TEST DATA\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"\\n--- TEST DATA ---\")\n",
    "print(\"Matriz de confusión:\")\n",
    "print(f\"TP: {TP}, FP: {FP}\")\n",
    "print(f\"FN: {FN}, TN: {TN}\")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Métrica de desempeño: Precisión, Sensibilidad y Especificidad\n",
    "print(\"Precisión:\", precision_metric*100, \"%\")\n",
    "print(\"Sensibilidad:\", sensibilidad*100, \" %\")\n",
    "print(\"Especificidad:\", especificidad*100, \" %\")\n",
    "\n",
    "\n",
    "# TRAIN DATA\n",
    "train_precision = accuracy_score(train_data[\"label\"], train_predicciones)\n",
    "train_cm = confusion_matrix(train_data[\"label\"], train_predicciones, labels=['ham', 'spam'])\n",
    "train_TP = train_cm[1, 1]\n",
    "train_FP = train_cm[0, 1]\n",
    "train_FN = train_cm[1, 0]\n",
    "train_TN = train_cm[0, 0]\n",
    "train_precision_metric = train_TP / (train_TP + train_FP) if (train_TP + train_FP) > 0 else 0\n",
    "train_sensibilidad = train_TP / (train_TP + train_FN) if (train_TP + train_FN) > 0 else 0\n",
    "train_especificidad = train_TN / (train_TN + train_FP) if (train_TN + train_FP) > 0 else 0\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"\\n--- TRAIN DATA ---\")\n",
    "print(\"Matriz de confusión:\")\n",
    "print(f\"TP: {train_TP}, FP: {train_FP}\")\n",
    "print(f\"FN: {train_FN}, TN: {train_TN}\")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Métrica de desempeño: Precisión, Sensibilidad y Especificidad\n",
    "print(\"Precisión:\", train_precision_metric*100, \"%\")\n",
    "print(\"Sensibilidad:\", train_sensibilidad*100, \" %\")\n",
    "print(\"Especificidad:\", train_especificidad*100, \" %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por medio de ello, se puede definir que el modelo sobre el subset de training tiene:<br>\n",
    "- **Precisión:** 97.57% <br>\n",
    "- **Sensibilidad:** 95.72% <br>\n",
    "- **Especificidad:** 99.64% <br>\n",
    "\n",
    "Y el modelo sobre el subset de testing tiene:<br>\n",
    "- **Precisión:** 89.72% <br>\n",
    "- **Sensibilidad:** 96.31% <br>\n",
    "- **Especificidad:** 98.11% <br>\n",
    "\n",
    "El modelo muestra un excelente desempeño en el conjunto de entrenamiento, con una precisión del 97.57%, una alta sensibilidad del 95.72% y una especificidad del 99.64%. Esto indica que el modelo clasifica correctamente la mayoría de los correos, tanto spam como ham, con un bajo índice de falsos positivos y falsos negativos. Sin embargo, en el conjunto de prueba, la precisión disminuye a 89.72%, lo que sugiere una menor capacidad para clasificar correctamente los correos en datos no vistos. A pesar de ello, la sensibilidad sigue siendo alta (96.31%), lo que indica que el modelo sigue detectando correctamente la mayoría de los correos spam, aunque la ligera disminución en la especificidad (98.11%) implica un pequeño aumento en los falsos positivos. Esta diferencia de rendimiento entre los conjuntos de entrenamiento y prueba sugiere que el modelo puede estar ligeramente sobreajustado, es decir, que se ha ajustado demasiado a los datos de entrenamiento y ha perdido algo de generalización. Aún así, su rendimiento general sigue siendo sólido, especialmente en la detección de correos spam.\n",
    "\n",
    "---\n",
    "\n",
    "### **Task 2.3** - Clasificación de mensajes futuros<br> \n",
    "Al finalizar el entrenamiento de su modelo, permita que se ingresen nuevos mensajes de forma individual desde su interfaz (ya sea en consola o en una interfaz gráfica). Y que estos se clasifiquen usando su modelo. Su programa deberá poder recibir cualquier tipo de mensaje y devolver la probabilidad de que sea spam y ham, así mismo como cuál es la decisión de clasificación de su modelo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mensaje:  hello, how are you?\n",
      "Ha sido clasificado como: ham\n",
      "\n",
      "El mensaje:  Yup... Ok i go home look at the timings then i msg ü again... Xuhui going to learn on 2nd may too but her lesson is at 8am\n",
      "Ha sido clasificado como: ham\n",
      "\n",
      "El mensaje:  XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL\n",
      "Ha sido clasificado como: spam\n",
      "\n",
      "El mensaje:  Yup... Ok i go home look at the timings then i msg ü again... Xuhui going to learn on 2nd may too but her lesson is at 8am\n",
      "Ha sido clasificado como: ham\n",
      "\n",
      "El mensaje:  Yup... Ok i go home look at the timings then i msg ü again... Xuhui going to learn on 2nd may too but her lesson is at 8am\n",
      "Ha sido clasificado como: ham\n",
      "\n",
      "SALIENDO... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Función para clasificar un mensaje ingresado por el usuario\n",
    "def clasificar_mensaje():\n",
    "    while True: # Usar un ciclo While\n",
    "        mensaje = input(\"Ingrese un mensaje para clasificar (o 'salir' para terminar): \") # Leer entrada\n",
    "        if mensaje.lower() == 'salir': # Si es salir\n",
    "            print(\"SALIENDO... \\n\")\n",
    "            break                      # Terminar ejecución\n",
    "        print(\"El mensaje: \" , mensaje)\n",
    "        mensaje = clean_text(mensaje) \n",
    "        clasificacion = calcular_probabilidades(mensaje, vocabulario, conteo_palabras, total_palabras, total_mensajes)\n",
    "        print(f\"Ha sido clasificado como: {clasificacion}\\n\")\n",
    "    \n",
    "clasificar_mensaje()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2.4** - Comparación con Librerías<br> \n",
    "Entrene un modelo de Bayes usando alguna librería ya existente como sklearn.naive_bayes.MultinomialNB en Python. Este deberá usar el mismo dataset dado, y deberá además dividirlo en training y testing como en el Task 2.1. Compare la métrica de desempeño tanto en training como en testing con la misma implementación que usted realizó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TRAIN DATA ---\n",
      "Matriz de confusión:\n",
      "TP: 560, FP: 14\n",
      "FN: 24, TN: 3854\n",
      "------------------------------------------\n",
      "Precisión: 97.5609756097561 %\n",
      "Sensibilidad: 95.8904109589041  %\n",
      "Especificidad: 97.5609756097561  %\n",
      "\n",
      "--- TEST DATA ---\n",
      "Matriz de confusión:\n",
      "TP: 151, FP: 4\n",
      "FN: 12, TN: 946\n",
      "------------------------------------------\n",
      "Precisión: 97.41935483870968 %\n",
      "Sensibilidad: 92.63803680981594  %\n",
      "Especificidad: 97.41935483870968  %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Abrir archivo \n",
    "with open(\"entrenamiento.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Convertir en un set donde se tenga la etiqueta y el mensaje\n",
    "data = []\n",
    "for line in lines:\n",
    "    parts = line.strip().split(\"\\t\", 1)  # Separar solo en la primera tabulación\n",
    "    if len(parts) == 2:\n",
    "        label, message = parts\n",
    "        data.append((label, message)) # Nombrar \"label\" si es Spam o Ham; y \"message\" al contenido en si del mensaje\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"label\", \"message\"])\n",
    "\n",
    "# Limpieza de datos | Eliminar ruido\n",
    "def clean_text(text):\n",
    "    text = text.lower()                      # Convertir a minúsculas (Normalizar)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # Eliminar caracteres especiales (Filtro ruido)\n",
    "    return text\n",
    "\n",
    "df[\"message\"] = df[\"message\"].apply(clean_text) # Despues de separar, aplicar limpieza a todos los datos\n",
    "\n",
    "# División en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorización de los mensajes (transformar texto en vectores numéricos)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data['message'])\n",
    "X_test = vectorizer.transform(test_data['message'])\n",
    "\n",
    "# Etiquetas (Spam o Ham)\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Modelo de Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Métricas de desempeño\n",
    "# TRAIN DATA\n",
    "conf_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "\n",
    "TP_train = conf_matrix_train[1, 1]  # spam correctamente clasificado\n",
    "FP_train = conf_matrix_train[0, 1]  # ham clasificado como spam\n",
    "FN_train = conf_matrix_train[1, 0]  # spam clasificado como ham\n",
    "TN_train = conf_matrix_train[0, 0]  # ham correctamente clasificado\n",
    "\n",
    "precision_train = precision_score(y_train, y_pred_train, pos_label='spam')\n",
    "recall_train = recall_score(y_train, y_pred_train, pos_label='spam')\n",
    "specificity_train = conf_matrix_train[1,1] / (conf_matrix_train[1,1] + conf_matrix_train[0,1])\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"\\n--- TRAIN DATA ---\")\n",
    "print(\"Matriz de confusión:\")\n",
    "print(f\"TP: {TP_train}, FP: {FP_train}\")\n",
    "print(f\"FN: {FN_train}, TN: {TN_train}\")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Métrica de desempeño: Precisión, Sensibilidad y Especificidad\n",
    "print(\"Precisión:\", precision_train*100, \"%\")\n",
    "print(\"Sensibilidad:\", recall_train*100, \" %\")\n",
    "print(\"Especificidad:\", specificity_train*100, \" %\")\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------------\n",
    "# TEST DATA\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "TP_test = conf_matrix_test[1, 1]  # spam correctamente clasificado\n",
    "FP_test = conf_matrix_test[0, 1]  # ham clasificado como spam\n",
    "FN_test = conf_matrix_test[1, 0]  # spam clasificado como ham\n",
    "TN_test = conf_matrix_test[0, 0]  # ham correctamente clasificado\n",
    "\n",
    "precision_test = precision_score(y_test, y_pred_test, pos_label='spam')\n",
    "recall_test = recall_score(y_test, y_pred_test, pos_label='spam')\n",
    "specificity_test = conf_matrix_test[1,1] / (conf_matrix_test[1,1] + conf_matrix_test[0,1])\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"\\n--- TEST DATA ---\")\n",
    "print(\"Matriz de confusión:\")\n",
    "print(f\"TP: {TP_test}, FP: {FP_test}\")\n",
    "print(f\"FN: {FN_test}, TN: {TN_test}\")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Métrica de desempeño: Precisión, Sensibilidad y Especificidad\n",
    "print(\"Precisión:\", precision_test*100, \"%\")\n",
    "print(\"Sensibilidad:\", recall_test*100, \" %\")\n",
    "print(\"Especificidad:\", specificity_test*100, \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por medio de ello, se puede definir que el modelo sobre el subset de training tiene:<br>\n",
    "- **Precisión:** 97.57% <br>\n",
    "- **Sensibilidad:** 95.89% <br>\n",
    "- **Especificidad:** 97.56% <br>\n",
    "\n",
    "Y el modelo sobre el subset de testing tiene:<br>\n",
    "- **Precisión:** 87.42% <br>\n",
    "- **Sensibilidad:** 92.63% <br>\n",
    "- **Especificidad:** 97.42% <br>\n",
    "\n",
    "**¿Cuál implementación lo hizo mejor? ¿Su implementación o la de la librería?**\n",
    "Comparando ambos modelos, podemos observar que ambos tienen un desempeño similar en el conjunto de entrenamiento, con una precisión idéntica del 97.57%. Sin embargo, al analizar el conjunto de prueba, el modelo hecho a mano tiene una mayor precisión (89.72%) en comparación con el modelo implementado con librerías (87.42%). El modelo hecho a mano muestra un mejor rendimiento en el conjunto de prueba, lo que podría indicar que está mejor ajustado para generalizar a datos no vistos. Sin embargo, esto no siempre es ideal. Un modelo que se ajusta demasiado a los datos de entrenamiento puede perder capacidad de generalización, y aunque la precisión sea mayor, es posible que no se mantenga ese buen rendimiento en situaciones más complejas o con datos adicionales.\n",
    "\n",
    "\n",
    "**¿Por qué cree que se debe esta diferencia?**\n",
    "Las librerías de machine learning, como las que se usan en bibliotecas como `scikit-learn`, suelen aplicar optimizaciones y técnicas de regularización que ayudan a evitar el sobreajuste, pero a costa de una ligera reducción en la precisión, especialmente en el conjunto de prueba. Aunque los resultados del modelo con librerías muestran una disminución en la precisión, su capacidad para evitar sobreajuste podría ser más efectiva a largo plazo, garantizando que el modelo no aprenda patrones espurios específicos de los datos de entrenamiento. Las librerías suelen incluir técnicas de preprocesamiento más robustas, manejo de datos faltantes, normalización, y validación cruzada que pueden ayudar a mejorar el rendimiento general. El modelo hecho a mano podría no haber utilizado todas estas técnicas o podría haber tenido limitaciones en su implementación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
