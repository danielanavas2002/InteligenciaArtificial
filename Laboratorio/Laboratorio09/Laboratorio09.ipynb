{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd65cf8",
   "metadata": {},
   "source": [
    "# **Laboratorio 9**\n",
    "**Daniela Navas**\n",
    "\n",
    "## **Task 1** - Teoría\n",
    "\n",
    "**Responda las siguientes preguntas de forma clara y concisa, pueden subir un PDF o bien dentro del mismo Jupyter Notebook.**<br> \n",
    "**1. Diga cual es la diferencia entre Modelos de Markov y Hidden Markov Models**<br>\n",
    "En los **Modelos de Markov** los estados son directamente observables. La probabilidad de transición entre estados depende únicamente del estado actual, no de los estados anteriores. Se utilizan comúnmente en aplicaciones donde los estados son visibles, como la predicción del clima o la generación de texto. En cambio, en los **Hidden Markov Models (HMM)** los estados no son directamente observables (son \"ocultos\"). En cambio, se observan emisiones que dependen de estos estados ocultos. Los HMM son útiles en situaciones donde los estados subyacentes no pueden ser observados directamente, como en el reconocimiento de voz o la bioinformática.\n",
    "\n",
    "**2. Investigue qué son los factorial HMM (Hidden Markov Models)**<br>\n",
    "Los factorial HMM son una extensión de los HMM estándar. En lugar de tener una sola cadena de estados ocultos, los factorial HMM tienen múltiples cadenas de estados ocultos que interactúan entre sí. Esto permite modelar sistemas más complejos donde múltiples factores pueden influir en las observaciones. Se utilizan en aplicaciones como el análisis de datos multivariados y la modelación de sistemas biológicos.\n",
    "\n",
    "**3. Especifique en sus propias palabras el algoritmo Forward Backward para HMM**<br>\n",
    "El algoritmo Forward Backward es un método de inferencia para HMM que calcula las probabilidades posteriores de los estados ocultos dados una secuencia de observaciones. Se realiza en dos pasos:\n",
    "1. **Forward:** Calcula las probabilidades de estar en cada estado en cada punto de tiempo, dado las observaciones hasta ese punto.\n",
    "2. **Backward:** Calcula las probabilidades de observar las secuencias restantes desde cada punto de tiempo hacia adelante. Al combinar estas probabilidades, se obtiene la distribución de los estados en cualquier punto de tiempo dado toda la secuencia de observaciones.\n",
    "\n",
    "**4. En el algoritmo de Forward Backward, por qué es necesario el paso de Backward (puede escribir ejemplos o casos para responder esta pregunta)**<br>\n",
    "El paso de Backward es crucial porque permite incorporar información futura en el cálculo de las probabilidades de los estados actuales. Sin este paso, solo se tendría en cuenta la información pasada y presente, lo que podría llevar a estimaciones menos precisas. Por ejemplo, si estás modelando el reconocimiento de voz, la información sobre las palabras futuras puede ayudar a determinar mejor los estados actuales de los fonemas.\n",
    "\n",
    "---\n",
    "\n",
    "## **Task 2** - Algoritmo Forward Backward en HMM \n",
    "El algoritmo forward-backward se basa en una forma de programación dinámica. Para este task deberán investigar sobre el mismo. En este ejercicio estamos ante un modelo meteorológico representado por un Modelo Oculto de Markov (HMM) con dos estados: \"Soleado\" y \"Lluvioso\". Queremos predecir el tiempo en un día determinado basándonos en las observaciones de si el día anterior estuvo soleado o lluvioso.\n",
    "\n",
    "Con esto, considere lo siguiente: \n",
    "1. Defina los parámetros del modelo oculto de Markov (HMM), incluidos estados, observaciones, probabilidades iniciales, probabilidades de transición y probabilidades de emisión. \n",
    "2. Cree una instancia de la clase HMM con los parámetros definidos. \n",
    "3. Genere una secuencia de observaciones utilizando el método generate_sequence. Este paso es opcional pero útil para realizar pruebas. \n",
    "4. Utilice el método forward para calcular las probabilidades directas, que representan la probabilidad de observar una secuencia particular de observaciones hasta un paso de tiempo específico y estar en un estado particular en ese paso de tiempo. \n",
    "5. Utilice el método backward para calcular las probabilidades hacia atrás, que representan la probabilidad de observar la secuencia restante desde un paso de tiempo específico hasta el final de la secuencia, dado que el sistema se encuentra en un estado particular en ese paso de tiempo. \n",
    "6. Utilice el método compute_state_probabilities para calcular las probabilidades de estar en cada estado en cada paso de tiempo dada la secuencia observada. Este paso implica combinar las probabilidades hacia adelante y hacia atrás. \n",
    "7. Imprima o analice las probabilidades calculadas según sea necesario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44348c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Secuencia:\n",
      "Rainy -> Rainy -> Sunny -> Sunny -> Rainy\n",
      "\n",
      "Probabilidades Forward:\n",
      "Paso 1:\n",
      "  Sunny : 10.00%\n",
      "  Rainy : 35.00%\n",
      "-------------------------\n",
      "Paso 2:\n",
      "  Sunny : 4.40%\n",
      "  Rainy : 16.10%\n",
      "-------------------------\n",
      "Paso 3:\n",
      "  Sunny : 7.97%\n",
      "  Rainy : 3.16%\n",
      "-------------------------\n",
      "Paso 4:\n",
      "  Sunny : 6.11%\n",
      "  Rainy : 1.05%\n",
      "-------------------------\n",
      "Paso 5:\n",
      "  Sunny : 1.06%\n",
      "  Rainy : 1.30%\n",
      "-------------------------\n",
      "\n",
      "Probabilidades Backward:\n",
      "Paso 1:\n",
      "  Sunny : 3.92%\n",
      "  Rainy : 5.62%\n",
      "-------------------------\n",
      "Paso 2:\n",
      "  Sunny : 15.32%\n",
      "  Rainy : 10.45%\n",
      "-------------------------\n",
      "Paso 3:\n",
      "  Sunny : 22.20%\n",
      "  Rainy : 18.60%\n",
      "-------------------------\n",
      "Paso 4:\n",
      "  Sunny : 30.00%\n",
      "  Rainy : 50.00%\n",
      "-------------------------\n",
      "Paso 5:\n",
      "  Sunny : 100.00%\n",
      "  Rainy : 100.00%\n",
      "-------------------------\n",
      "\n",
      "Probabilidades de Estado (Forward-Backward):\n",
      "Paso 1:\n",
      "  Sunny : 16.61%\n",
      "  Rainy : 83.39%\n",
      "-------------------------\n",
      "Paso 2:\n",
      "  Sunny : 28.61%\n",
      "  Rainy : 71.39%\n",
      "-------------------------\n",
      "Paso 3:\n",
      "  Sunny : 75.05%\n",
      "  Rainy : 24.95%\n",
      "-------------------------\n",
      "Paso 4:\n",
      "  Sunny : 77.78%\n",
      "  Rainy : 22.22%\n",
      "-------------------------\n",
      "Paso 5:\n",
      "  Sunny : 45.04%\n",
      "  Rainy : 54.96%\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------- \n",
    "#\n",
    "# Definición de la clase HMM (Hidden Markov Model)\n",
    "# \n",
    "# -------------------------------------------------------\n",
    "class HMM:\n",
    "    def __init__(self, states, observations, initial_prob, transition_prob, emission_prob):\n",
    "        \"\"\"\n",
    "        Constructor del modelo HMM.\n",
    "        \n",
    "        Params:\n",
    "        - states: lista de estados ocultos posibles.\n",
    "        - observations: lista de observaciones posibles.\n",
    "        - initial_prob: diccionario con las probabilidades iniciales de cada estado.\n",
    "        - transition_prob: diccionario de diccionarios que representa las probabilidades de transición entre estados.\n",
    "        - emission_prob: diccionario de diccionarios que representa las probabilidades de emisión de observaciones dado un estado.\n",
    "        \"\"\"\n",
    "\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.initial_prob = initial_prob\n",
    "        self.transition_prob = transition_prob\n",
    "        self.emission_prob = emission_prob\n",
    "\n",
    "    def generate_sequence(self, length):\n",
    "        \"\"\"\n",
    "        Genera una secuencia de observaciones de una longitud dada a partir del modelo HMM.\n",
    "\n",
    "        Param:\n",
    "        - length: longitud de la secuencia a generar.\n",
    "\n",
    "        Return:\n",
    "        - sequence: lista de observaciones generadas por el modelo.\n",
    "        \"\"\"\n",
    "\n",
    "        import random # Librería para seleccionar aleatoriamente elementos\n",
    "        sequence = [] # Lista para almacenar la secuencia de observaciones generadas\n",
    "\n",
    "        # Se elige un estado inicial basado en las probabilidades iniciales\n",
    "        current_state = random.choices(self.states, weights=[self.initial_prob[s] for s in self.states])[0]\n",
    "\n",
    "        # Generación de la secuencia de observaciones\n",
    "        for _ in range(length):\n",
    "            # Se genera una observación basada en la distribución de emisión del estado actual\n",
    "            observation = random.choices(self.observations, weights=[self.emission_prob[current_state][o] for o in self.observations])[0]\n",
    "            sequence.append(observation) # Se agrega la observación a la secuencia\n",
    "            current_state = random.choices(self.states, weights=[self.transition_prob[current_state][s] for s in self.states])[0] # Elegir el siguiente estado basado en las probabilidades de transición\n",
    "        return sequence  # Retorna la secuencia de observaciones generada\n",
    "\n",
    "    def forward(self, observations):\n",
    "        \"\"\"\n",
    "        Calcula la matriz de probabilidades hacia adelante (alpha) para una secuencia de observaciones.\n",
    "\n",
    "        Param:\n",
    "        - observations: lista de observaciones sobre las que se evaluará el modelo.\n",
    "\n",
    "        Return:\n",
    "        - alpha: lista de diccionarios, donde cada uno contiene las probabilidades de cada estado \n",
    "                 en cada instante de tiempo dado lo observado hasta ese punto.\n",
    "        \"\"\"\n",
    "\n",
    "        alpha = [{}] # Lista de diccionarios: alpha[t][state] representa la probabilidad de estar en 'state' en el tiempo t dado las observaciones hasta t\n",
    "        \n",
    "        # Inicialización en t = 0 con la primera observación\n",
    "        for state in self.states:\n",
    "            alpha[0][state] = self.initial_prob[state] * self.emission_prob[state][observations[0]]\n",
    "\n",
    "        # Recursión para t > 0\n",
    "        for t in range(1, len(observations)):\n",
    "            alpha.append({})\n",
    "            for curr_state in self.states:\n",
    "                # Suma de las probabilidades desde todos los estados anteriores al estado actual\n",
    "                alpha[t][curr_state] = sum(alpha[t - 1][prev_state] * \n",
    "                                           self.transition_prob[prev_state][curr_state] for prev_state in self.states) * \\\n",
    "                                           self.emission_prob[curr_state][observations[t]]\n",
    "        return alpha # Devuelve la matriz de probabilidades hacia adelante\n",
    "\n",
    "    def backward(self, observations):\n",
    "        \"\"\"\n",
    "        Calcula la matriz de probabilidades hacia atrás (beta) para una secuencia de observaciones.\n",
    "\n",
    "        Param:\n",
    "        - observations: lista de observaciones sobre las que se evaluará el modelo.\n",
    "\n",
    "        Return:\n",
    "        - beta: lista de diccionarios, donde cada uno contiene las probabilidades de cada estado \n",
    "                en cada instante de tiempo dado lo que falta por observar desde ese punto.\n",
    "        \"\"\"\n",
    "\n",
    "        beta = [{} for _ in range(len(observations))] # Inicialización de la matriz beta con diccionarios vacíos\n",
    "        for state in self.states:\n",
    "            beta[-1][state] = 1.0  # Inicializar al final\n",
    "\n",
    "        # Inicializar en el último tiempo con 1.0 para todos los estados (es el punto de partida de la recursión hacia atrás)\n",
    "        for t in reversed(range(len(observations) - 1)):\n",
    "            for state in self.states:\n",
    "                beta[t][state] = sum(\n",
    "                    self.transition_prob[state][next_state] *                         # probabilidad de transición al siguiente estado \n",
    "                    self.emission_prob[next_state][observations[t + 1]] *             # probabilidad de emitir la siguiente observación\n",
    "                    beta[t + 1][next_state]                                           # beta del siguiente estado\n",
    "                    for next_state in self.states\n",
    "                )\n",
    "        return beta # Devuelve la matriz de probabilidades hacia atrás\n",
    "\n",
    "    def compute_state_probabilities(self, observations):\n",
    "        \"\"\"\n",
    "        Calcula la probabilidad de cada estado en cada instante de tiempo dado una secuencia de observaciones,\n",
    "        utilizando los algoritmos forward y backward.\n",
    "\n",
    "        Param:\n",
    "        - observations: lista de observaciones para las cuales se calcularán las probabilidades de estado.\n",
    "\n",
    "        Return:\n",
    "        - state_probs: lista de diccionarios, donde cada diccionario representa las probabilidades \n",
    "                       normalizadas de estar en cada estado en el tiempo t dado toda la secuencia observada.\n",
    "        \"\"\"\n",
    "\n",
    "        forward_probs = self.forward(observations)   # Calcular las probabilidades hacia adelante (alpha)\n",
    "        backward_probs = self.backward(observations) # Calcular las probabilidades hacia atrás (beta)\n",
    "        state_probs = []                             # Lista para almacenar las probabilidades por tiempo\n",
    "\n",
    "        # Para cada instante de tiempo en la secuencia de observaciones\n",
    "        for t in range(len(observations)):\n",
    "            # Calcular la suma total (normalización) de las probabilidades forward * backward para todos los estados\n",
    "            total = sum(forward_probs[t][s] * backward_probs[t][s] for s in self.states)\n",
    "            \n",
    "            # Calcular la probabilidad normalizada para cada estado en el tiempo t\n",
    "            state_probs.append({\n",
    "                s: (forward_probs[t][s] * backward_probs[t][s]) / total for s in self.states\n",
    "            })\n",
    "        return state_probs # Devuelve la lista de distribuciones de probabilidad por estado y tiempo\n",
    "\n",
    "def imprimir_probabilidades(titulo, probs):\n",
    "    \"\"\"\n",
    "    Imprime de forma formateada las probabilidades de los estados en cada paso de tiempo.\n",
    "\n",
    "    Param:\n",
    "    - titulo: título a mostrar antes de imprimir los resultados.\n",
    "    - probs: lista de diccionarios, donde cada diccionario contiene las probabilidades \n",
    "             de los estados en un instante de tiempo (como el resultado de forward, backward o compute_state_probabilities).\n",
    "    \"\"\"\n",
    "    print(f\"\\n{titulo}:\") # Imprime el título como encabezado\n",
    "\n",
    "    # Itera sobre la lista de probabilidades por tiempo\n",
    "    for t, paso in enumerate(probs):\n",
    "        print(f\"Paso {t+1}:\")\n",
    "        for estado in paso:\n",
    "            print(f\"  {estado:<6}: {paso[estado]*100:.2f}%\") # Imprimir cada estado y su probabilidad en porcentaje con dos decimales\n",
    "        print(\"-\" * 25)\n",
    "\n",
    "# Parámetros del modelo (Definidos según el código brindado)\n",
    "states = ['Sunny', 'Rainy']\n",
    "observations = ['Sunny', 'Sunny', 'Rainy']\n",
    "initial_prob = {'Sunny': 0.5, 'Rainy': 0.5}\n",
    "transition_prob = {\n",
    "    'Sunny': {'Sunny': 0.8, 'Rainy': 0.2},\n",
    "    'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}\n",
    "}\n",
    "emission_prob = {\n",
    "    'Sunny': {'Sunny': 0.8, 'Rainy': 0.2},\n",
    "    'Rainy': {'Sunny': 0.3, 'Rainy': 0.7}\n",
    "}\n",
    "\n",
    "# ==================================================================================================================\n",
    "# Instancia del modelo\n",
    "hmm = HMM(states, observations, initial_prob, transition_prob, emission_prob)\n",
    "\n",
    "# 1. Generar secuencia de observaciones\n",
    "obs_sequence = hmm.generate_sequence(5)\n",
    "\n",
    "# 2. Calcular forward\n",
    "forward_probs = hmm.forward(obs_sequence)\n",
    "\n",
    "# 3. Calcular backward\n",
    "backward_probs = hmm.backward(obs_sequence)\n",
    "\n",
    "# 4. Calcular probabilidades de estado\n",
    "state_probs = hmm.compute_state_probabilities(obs_sequence)\n",
    "\n",
    "# --------------------------------\n",
    "# Mostrar resultados \n",
    "print(\"\\nSecuencia:\")\n",
    "print(\" -> \".join(obs_sequence))\n",
    "\n",
    "imprimir_probabilidades(\"Probabilidades Forward\", forward_probs)\n",
    "imprimir_probabilidades(\"Probabilidades Backward\", backward_probs)\n",
    "imprimir_probabilidades(\"Probabilidades de Estado (Forward-Backward)\", state_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a27090",
   "metadata": {},
   "source": [
    "*(Para este set de resultados específicos)*\n",
    "\n",
    "El método **Forward** calcula las probabilidades de los estados ocultos considerando solo las observaciones anteriores. A medida que avanzan los pasos, se observa una disminución continua de las probabilidades, ya que el modelo solo tiene en cuenta la evidencia hasta el punto actual, sin considerar las observaciones futuras. Primero, la probabilidad de \"Rainy\" es bastante alta (35%), lo que refleja la primera observación (Rainy) y la transición probable a este estado. Sin embargo, las probabilidades de \"Sunny\" y \"Rainy\" son bajas en comparación, lo que indica incertidumbre debido a que no se tiene información de los pasos siguientes. A medida que avanzan los pasos, las probabilidades continúan disminuyendo, ya que el modelo no tiene acceso a las observaciones futuras. Esto lleva a una pérdida progresiva de certeza. Las probabilidades de \"Sunny\" y \"Rainy\" son bastante cercanas (1.06% y 1.30%), lo que refleja la alta incertidumbre al llegar al final de la secuencia.\n",
    "\n",
    "El método **Backward** calcula las probabilidades de los estados ocultos utilizando solo la información de las observaciones futuras, es decir, comienza desde el último paso y retrocede. Este enfoque da una visión más completa de las probabilidades, ya que las observaciones futuras refuerzan la estimación de los estados actuales. A medida que se retrocede, las probabilidades de \"Sunny\" y \"Rainy\" aumentan considerablemente. El modelo, al tener acceso a la información futura, ajusta sus creencias de manera más precisa, reflejando una mayor certeza sobre el estado subyacente. Las probabilidades en el paso 5 (100% para ambos estados) no son exactas en un sentido práctico, ya que el modelo está utilizando información que ya ha sido observada, pero muestra cómo el método **Backward** se ajusta completamente a los estados observados.\n",
    "\n",
    "En cambio, en **Forward-Backward** se combina lo mejor de ambos métodos, integrando la información de las observaciones pasadas y futuras. Esto da lugar a estimaciones más precisas de los estados ocultos, ya que se incorporan las evidencias completas para cada paso en la secuencia. El modelo predice una probabilidad bastante alta de \"Rainy\" (83.39%), ya que la información tanto pasada como futura fortalece esta estimación. Esto refleja la alta probabilidad de transición de \"Rainy\" a \"Rainy\" y la observación inicial.\n",
    "Las probabilidades para \"Sunny\" y \"Rainy\" en estos pasos se equilibran más que en el enfoque **Forward**. El modelo ajusta sus estimaciones con mayor precisión, ya que ya tiene en cuenta las observaciones futuras y las transiciones pasadas.\n",
    "En el último paso, se ve una ligera inclinación hacia \"Rainy\" (54.96%), lo que refleja cómo la secuencia de transiciones y las observaciones pasadas todavía influyen en el modelo, a pesar de la observación final de \"Rainy\".\n",
    "\n",
    "---\n",
    "\n",
    "**GITHUB:**\n",
    "https://github.com/danielanavas2002/InteligenciaArtificial/tree/main/Laboratorio/Laboratorio09"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
