{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Laboratorio 7**\n",
    "**Daniela Navas**\n",
    "\n",
    "## **Task 1** - Teoría\n",
    "\n",
    "**Responda las siguientes preguntas de forma clara y concisa, pueden subir un PDF o bien dentro del mismo Jupyter Notebook.**<br> \n",
    "**1. ¿Qué es el temporal difference learning y en qué se diferencia de los métodos tradicionales de aprendizaje supervisado? Explique el concepto de \"error de diferencia temporal\" y su papel en los algoritmos de aprendizaje por refuerzo**<br>\n",
    "TD Learning es un método de aprendizaje por refuerzo que combina ideas del aprendizaje supervisado y no supervisado. A diferencia de los métodos tradicionales de aprendizaje supervisado, que requieren un conjunto de datos etiquetados, TD Learning utiliza la experiencia directa del agente para aprender. El **\"error de diferencia temporal\"** es la diferencia entre el valor predicho y el valor real observado en el siguiente estado. Este error se utiliza para ajustar las estimaciones futuras. En los algoritmos de aprendizaje por refuerzo, el error de diferencia temporal ayuda a actualizar las políticas y valores de estado de manera más eficiente.\n",
    "\n",
    "**2. En el contexto de los juegos simultáneos, ¿cómo toman decisiones los jugadores sin conocer las acciones de sus oponentes? De un ejemplo de un escenario del mundo real que pueda modelarse como un juego simultáneo y discuta las estrategias que los jugadores podrían emplear en tal situación**<br>\n",
    "En juegos simultáneos, los jugadores toman decisiones sin conocer las acciones de sus oponentes. Esto se hace mediante la evaluación de estrategias y posibles resultados. Un ejemplo podría ser una subasta silenciosa, donde los participantes ofrecen precios sin saber las ofertas de los demás. Las estrategias pueden incluir ofrecer un precio que maximice la probabilidad de ganar sin exceder el valor percibido del objeto.\n",
    "\n",
    "**3. ¿Qué distingue los juegos de suma cero de los juegos de suma no cero y cómo afecta esta diferencia al proceso de toma de decisiones de los jugadores? Proporcione al menos un ejemplo de juegos que entren en la categoría de juegos de no suma cero y discuta las consideraciones estratégicas únicas involucradas**<br>\n",
    "En los juegos de suma cero, la ganancia de un jugador es exactamente igual a la pérdida del otro. En los juegos de no suma cero, los jugadores pueden beneficiarse mutuamente. Como ejemplo esta la negociación comercial entre dos empresas. Aquí, ambas partes pueden encontrar una solución que beneficie a ambas, como un acuerdo de colaboración.\n",
    "\n",
    "**4. ¿Cómo se aplica el concepto de equilibrio de Nash a los juegos simultáneos? Explicar cómo el equilibrio de Nash representa una solución estable en la que ningún jugador tiene un incentivo para desviarse unilateralmente de la estrategia elegida**<br>\n",
    "El equilibrio de Nash se aplica cuando cada jugador elige una estrategia óptima, considerando las estrategias de los demás. Ningún jugador tiene un incentivo para cambiar unilateralmente su estrategia. La **estabilidad** representa una solución estable porque todos los jugadores están en su mejor respuesta dada la estrategia de los otros jugadores.\n",
    "\n",
    "**5. Discuta la aplicación del temporal difference learning en el modelado y optimización de procesos de toma de decisiones en entornos dinámicos. ¿Cómo maneja el temporal difference learning el equilibrio entre exploración y explotación y cuáles son algunos de los desafíos asociados con su implementación en la práctica?**<br>\n",
    "- **Modelado y optimización:** TD Learning se utiliza para modelar y optimizar procesos de toma de decisiones en entornos donde las condiciones cambian con el tiempo.\n",
    "- **Equilibrio entre exploración y explotación:** TD Learning maneja este equilibrio mediante la actualización continua de las estimaciones de valor, permitiendo al agente explorar nuevas estrategias mientras explota las conocidas.\n",
    "- **Desafíos:** Algunos desafíos incluyen la necesidad de un balance adecuado entre exploración y explotación y la complejidad computacional asociada con la actualización de valores en tiempo real."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
